{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Creating a Single Value for GCconnex usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('ggplot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing three different datasets\n",
    "data_path = \"/Users/Owner/Documents/Work_transfer/CLSep/Valuesys/Data/\"\n",
    "collcols = ['GUID1', 'GUID2', 'Date']\n",
    "groupscols = ['GUID1', 'Group', 'Date']\n",
    "replcols = ['GUID1', 'Topic', 'Date']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colleagues = pd.read_csv(data_path + 'Colleagues.csv', header = None, names = collcols)\n",
    "groups = pd.read_csv(data_path + 'Groups.csv', header = None, names = groupscols)\n",
    "replies = pd.read_csv(data_path + 'Replies.csv', header = None, names = replcols)\n",
    "\n",
    "#Counting how much of what each user has done\n",
    "\n",
    "colcount = colleagues.groupby('GUID1').count().reset_index()\n",
    "colcount = colcount[['GUID1', 'GUID2']]\n",
    "colcount.columns = ['GUID', 'Colleagues']\n",
    "\n",
    "\n",
    "grpcount = groups.groupby('GUID1').count().reset_index()\n",
    "grpcount = grpcount[['GUID1', 'Group']]\n",
    "grpcount.columns = ['GUID', 'Groups']\n",
    "\n",
    "repcount = replies.groupby('GUID1').count().reset_index()\n",
    "repcount = repcount[['GUID1', 'Topic']]\n",
    "repcount.columns = ['GUID', 'Comments']\n",
    "replies.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#Creating the activity matrix\n",
    "activity = pd.merge(colcount, grpcount, how = \"outer\", on = 'GUID')\n",
    "activity = pd.merge(activity, repcount, how = \"outer\", on = 'GUID')\n",
    "\n",
    "activity = activity.fillna(0)\n",
    "activity.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "activity[activity['GUID'] == 10242025]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logcoll = activity['Colleagues'][activity['Colleagues'] > 0].reset_index(drop = True)\n",
    "logcoll = np.log(logcoll)\n",
    "\n",
    "loggrp = activity['Groups'][activity['Groups'] > 0].reset_index(drop = True)\n",
    "\n",
    "loggrp = np.log(loggrp)\n",
    "\n",
    "logcom = activity['Comments'][activity['Comments'] > 0].reset_index(drop = True)\n",
    "\n",
    "logcom = np.log(logcom)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logcom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#looking at data is a good thing\n",
    "x = plt.hist(logcoll, histtype = 'step', label = 'Colleagues', linewidth = '2')\n",
    "\n",
    "\n",
    "#a very good thing\n",
    "y = plt.hist(loggrp, histtype = 'step', label = 'Groups', linewidth = '2')\n",
    "\n",
    "\n",
    "#Martha Stewart\n",
    "z = plt.hist(logcom, histtype = 'step', label = 'Comments', linewidth = '2')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Distribution of Types of Activity on GCconnex')\n",
    "plt.xlabel('Log(Value)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#A really interesting thing about this plot is the intersection between colleagues and groups.\n",
    "#The fact that comments is the smallest of the three is not shocking at all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loggrp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logs = [logcoll, loggrp, logcom]\n",
    "logact = pd.DataFrame(logs).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logact = logact.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logact.describe() #We're left with 6890 people who have done at least one of everything on the network\n",
    "#Interesting shit already"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The formula for the score is as follows:\n",
    "$$Where   c_i = ln(colleagues_i), r_i = ln(comments_i), g_i = ln(groups)_i,$$\n",
    "\n",
    "$$sumscore_i = c_i + r_i + g_i$$\n",
    "\n",
    "$$pdtsumscore_i = c_i + r_i + g_i + c_i*r_i + c_i*g_i + r_i*g_i$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logact['Sum Score'] = logact['Colleagues'] + logact['Comments'] + logact['Groups']\n",
    "logact['Pdt Sum Score'] = logact['Colleagues'] + logact['Comments'] + logact['Groups'] + logact['Colleagues']*logact['Comments'] +  logact['Colleagues']*logact['Groups'] + logact['Groups']*logact['Comments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logact.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sumscore = logact['Sum Score'].reset_index(drop = True)\n",
    "psumscore = logact['Pdt Sum Score'].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ss = plt.hist(sumscore, linewidth = '2', label = 'Sum Score', histtype = 'step')\n",
    "pss = plt.hist(psumscore, linewidth = '2', label = 'Pdt Sum Score', histtype = 'step')\n",
    "plt.legend()\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('BL0CH')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lsumscore = np.log(sumscore[sumscore > 0]).reset_index(drop = True)\n",
    "lpsumscore = np.log(psumscore[psumscore > 0]).reset_index(drop = True)\n",
    "\n",
    "lss = plt.hist(lsumscore, linewidth = '2', label = 'Ln(Sum Score)', histtype = 'step')\n",
    "lpss = plt.hist(lpsumscore, linewidth = '2', label = 'Ln(Pdt Sum Score)', histtype = 'step')\n",
    "plt.legend()\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('BL0CH')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Discussion on Above\n",
    "\n",
    "## Here we showed that if you take the logarithm of a Power Law distribution enough, it becomes similar to a normal distributions. Normal Distributions are nice because they are mathematically convenient, but are they reflective of what's going on in the network?\n",
    "\n",
    "### In this method, while diminishing marginal returns are factored into the equation (which is a fair assumption to make), each of the activities are equally weighted (1 colleague = 1 comment), which is not indicative of the effort in each activity. This method is also very restrictive. We started with nearly 90000 users, and the end rank only shows 9000 users. This means two things, 10% of our users have done 2 of each comment, colleague and group post, and even then, a strong amount of users have not done more than that.\n",
    "\n",
    "### While the normal distribution is mathematically convenient, it seems that making the assumption of a normal distribution may be a little far fetched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sumscore.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### From 90000 -> 9000. The advantage is that it guts the people who don't have more than two of each action, and therefore would give a poor score anyway.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### An alternative measurement that would consider more individuals in the ranking process would be a simple weighted process of counting how many connections as the proportion of total connections that exist in the system. \n",
    "## For example:\n",
    "\n",
    "# $$comment_i^w = \\frac{comment_i}{\\Sigma_{j=1}^J(comment_j)} $$\n",
    "\n",
    "\n",
    "### This would result in very small values, but that's not the issue at the moment. The issue is getting appropriate rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Calculating Sums\n",
    "\n",
    "colsum = activity['Colleagues'].sum()\n",
    "comsum = activity['Comments'].sum()\n",
    "grpsum = activity['Groups'].sum()\n",
    "\n",
    "#Also log colsums as an experiment\n",
    "\n",
    "\n",
    "lcolsum = np.log(colsum)\n",
    "lcomsum = np.log(comsum)\n",
    "lgrpsum = np.log(grpsum)\n",
    "print (colsum)\n",
    "print (comsum)\n",
    "print (grpsum)\n",
    "print (\" \")\n",
    "\n",
    "print (lcolsum)\n",
    "print (lcomsum)\n",
    "print (lgrpsum)\n",
    "\n",
    "sumslist = [colsum, comsum, grpsum]\n",
    "lsumslist = [lcolsum, lcomsum, lgrpsum]\n",
    "print (\"\")\n",
    "\n",
    "for i in sumslist:\n",
    "    for j in sumslist:\n",
    "        if i/j <= 1:\n",
    "            pass\n",
    "        else:\n",
    "            print (i/j)\n",
    "print (\"\")\n",
    "\n",
    "for i in lsumslist:\n",
    "    for j in lsumslist:\n",
    "        if i/j <= 1:\n",
    "            pass\n",
    "        else:\n",
    "            print (i/j)\n",
    "            \n",
    "            \n",
    "#From the above calculations, it's pretty clear that using logarithms is dumb\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wcol = activity['Colleagues']/colsum\n",
    "wcom = activity['Comments']/comsum\n",
    "wgrp = activity['Groups']/grpsum\n",
    "\n",
    "\n",
    "weightedactivity = pd.DataFrame([wcol, wcom, wgrp]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for brevity, wa = weightedactivity\n",
    "\n",
    "wa = weightedactivity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wa['Sum Score'] = wa['Colleagues'] + wa['Comments'] + wa['Groups']\n",
    "wa['Pdt Sum Score'] = wa['Colleagues'] + wa['Comments'] + wa['Groups'] + wa['Colleagues']*wa['Comments'] +  wa['Colleagues']*wa['Groups'] + wa['Groups']*wa['Comments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "diff = -(wa['Sum Score'] - wa['Pdt Sum Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wa['Sum Score'] *= 1000\n",
    "wa['Pdt Sum Score'] *= 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wa.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(np.log(wa['Sum Score']), histtype = 'step')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#We're left with a power law distribution, but that's actually probably not a bad thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lwa = weightedactivity[['Colleagues', 'Comments', 'Groups']]\n",
    "lwa.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lwa = lwa.replace(0, 0.00000001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aiming for a more normal distribution follows these assumptions:\n",
    "### 1. Value from using social networks diminishes the greater you use it. $$u({\\lambda}x) < {\\lambda}u(x)$$\n",
    "### 2. There exists an \"average\" value that represents a majority of the population aka Bell curve in the middle\n",
    "\n",
    "\n",
    "#### Point 2 has a subtle nuance. It basically means that the mid point of utility from the social network is what the average user experiences. This point is very clearly untrue, so trying to make a normal distribution would make inference to reality difficult."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in lwa:\n",
    "\n",
    "    \n",
    "    \n",
    "    lwa[i] = np.log(lwa[i])\n",
    "    lwa[i] = lwa[i].fillna(0)\n",
    "    lwa[i] = lwa[i] + abs(min(lwa[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lwa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lwa['Sum Score'] = lwa['Colleagues'] + lwa['Comments'] + lwa['Groups']\n",
    "lwa['Pdt Sum Score'] = lwa['Colleagues'] + lwa['Comments'] + lwa['Groups'] + lwa['Colleagues']*lwa['Comments'] +  lwa['Colleagues']*lwa['Groups'] + lwa['Groups']*lwa['Comments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lwa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(np.log(lwa['Pdt Sum Score']), histtype = 'step' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
