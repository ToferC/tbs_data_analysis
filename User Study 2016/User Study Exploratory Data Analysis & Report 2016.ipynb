{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to perform some exploratory analysis of the 2016 User Study survey. Wahida Chowdhury and I will be working together and collaborating on ideas for this study, however this work will be largely data and visualization focused.\n",
    "\n",
    "The User Study gathered nearly 5000 responses, anonymously asking demographic and usage information about participants' usage of the various GCTools (GCconnex, GCpedia, GCIntranet). Users' responses can be used to gather feedback on the strengths and weaknesses of the GCTools, as well as providing a description of the tools' userbases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file will document my research progress, starting from the very beggining of my analysis. This file will not include textual analysis, but this will be saved later for another notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#I will import more sophisticated packages (ie scklearn packages) as they are needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#First we will start by importing the data. Wahida gave me two sheets, one of which contains mostly completed responses,\n",
    "#The other contains mostly incomplete responses.\n",
    "#Here is the first one\n",
    "data_path = r\"/Users/Owner/Documents/Work_transfer/User Study 2016/\"\n",
    "df = pd.read_excel(data_path+\"User Study 2016.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.filter(regex = \"Other\").describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is way too big. We're gonna have to crunch this down a bit for sure.\n",
    "This survey is most useful when we can link the answers to the demographics. \n",
    "I'm going to start by taking a few key questions from the data and putting that into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3 = df.filter(regex = \"P3Q\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3['Participant'] = df['participant no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3columns = ['Department', 'DepartmentOther', 'CompressedWeek', 'FlexibleWork', 'Telework', 'JobSharing',\n",
    "              'IncomeAveraging','NoArrangement', 'Status', 'StatusOther', 'Community', 'Tenure', 'TenureOther',\n",
    "              'SMLevel', 'Language', 'Region', 'Age', 'Gender', 'Education', 'Participant']\n",
    "df3.columns = df3columns\n",
    "\n",
    "df3 = df3[['Participant', 'Department', 'DepartmentOther', 'CompressedWeek', 'FlexibleWork', 'Telework', 'JobSharing',\n",
    "              'IncomeAveraging','NoArrangement', 'Status', 'StatusOther', 'Community', 'Tenure', 'TenureOther',\n",
    "              'SMLevel', 'Language', 'Region', 'Age', 'Gender', 'Education']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3.describe(include  = \"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all the demographic information of the participants neatly organized in one table, that can still be easily combined with other tables. For now I just want demographic info. We will dig a little bit deeper soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "departments = df3['Department'].value_counts().reset_index()\n",
    "departmentsother = df3['DepartmentOther'].value_counts().reset_index()# We cna ignore departments other\n",
    "departments # Group similar dept's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This actually tells us nothing that we couldn't already find\n",
    "\n",
    "gender = df3['Gender'].value_counts().reset_index()\n",
    "age = df3['Age'].value_counts().reset_index()\n",
    "smlevel = df3['SMLevel'].value_counts().reset_index()\n",
    "education = df3['Education'].value_counts().reset_index()\n",
    "community = df3['Community'].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "community\n",
    "community_plot = community.set_index('index')\n",
    "\n",
    "\n",
    "ax = community_plot.plot.bar(title = \"Responses By Area of Work\")\n",
    "ax.set_xlabel(\"Area of Work\")\n",
    "ax.set_ylabel(\"Number of Respondents\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "community_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an important table (probably one of the most directly important tables here). I don't know the statistics for public servants per category, but an interesting (although probably impossible) task would be to look at the proportion.\n",
    "\n",
    "We'll use this later when we start looking at behaviour connected to employment group.\n",
    "\n",
    "# GCconnex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfconnex = df.filter(regex = \"GCc\")\n",
    "dfconnex['Participant'] = df['participant no'] # This will be used to the tables\n",
    "\n",
    "#I'm gonna take this moment to complain about the amount of columns I have to rename :'( "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (\"I'm so afraid of having to deal with\", len(dfconnex.columns)+1,\"columns :'(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfconnexcol = ['Aware', 'UsageLength', 'UsageLengthOther', 'NoUseWhy', 'NoUseCollab', 'NoUsePublic', 'NoUseSupervisor', 'NoUseNoTime',\n",
    "               'PplNoUse', 'NoToolsInfo', 'NoPurpose', 'Other', 'OtherResponse', 'HowOftenUse', 'WhyUseConnect',\n",
    "               'WhyUsePlan', 'WhyUseCoCreate', 'WhyUseFeedback', 'WhyUseOrgShareInfo', 'WhyUseFindReUseInfo',\n",
    "               'WhyUseOfficialContent', 'WhyUseFindNewPos', 'WhyUseCareerDev',\n",
    "               'WhyUseChat', 'WhyUseOther', 'WhyUseReason', 'EasyUse', 'EasyInfo', 'InfoUseful', 'LoadQuickly',\n",
    "               'TailoredContent', 'AdequateFeedback', 'BuildRelationships', 'EasyProfile', 'EasyNewsFeed',\n",
    "               'EasyOnBoarding', 'EasyNotifications', 'EasyInformationGroup', 'EasyCollabGroup', 'EasyWriteBlog',\n",
    "               'EasyReadBlog', 'EasyWriteWire', 'EasyReadWire', 'EasyPostImage', 'EasyViewImage', 'EasyCreateBM',\n",
    "               'EasyCreatePolls', 'EasyWidgets', 'EasyNoteIdeas', 'EasyUseChat', 'EasyUseChatrooms', 'EasyUseSearch',\n",
    "               'EasyOther', 'WhyNotEasy', 'FeaturesWant', 'Helpopen', 'HelpAgile', 'HelpCollab', 'IsSecure',\n",
    "               'IsReliable', 'IsCompFunctional', 'IsAlignedGovGoals', 'IsGoodSourceInfo', 'IsGoodCentralHub', 'OtherBenefits',\n",
    "               'Participant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfconnex.columns = dfconnexcol # There's a piece of missing data in each entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfconnex = dfconnex[['Participant', 'Aware', 'UsageLength', 'UsageLengthOther', 'NoUseWhy', 'NoUseCollab', 'NoUsePublic', 'NoUseSupervisor', 'NoUseNoTime',\n",
    "               'PplNoUse', 'NoToolsInfo', 'NoPurpose', 'Other', 'OtherResponse', 'HowOftenUse', 'WhyUseConnect',\n",
    "               'WhyUsePlan', 'WhyUseCoCreate', 'WhyUseFeedback', 'WhyUseOrgShareInfo', 'WhyUseFindReUseInfo',\n",
    "               'WhyUseOfficialContent', 'WhyUseFindNewPos', 'WhyUseCareerDev',\n",
    "               'WhyUseChat', 'WhyUseOther', 'WhyUseReason', 'EasyUse', 'EasyInfo', 'InfoUseful', 'LoadQuickly',\n",
    "               'TailoredContent', 'AdequateFeedback', 'BuildRelationships', 'EasyProfile', 'EasyNewsFeed',\n",
    "               'EasyOnBoarding', 'EasyNotifications', 'EasyInformationGroup', 'EasyCollabGroup', 'EasyWriteBlog',\n",
    "               'EasyReadBlog', 'EasyWriteWire', 'EasyReadWire', 'EasyPostImage', 'EasyViewImage', 'EasyCreateBM',\n",
    "               'EasyCreatePolls', 'EasyWidgets', 'EasyNoteIdeas', 'EasyUseChat', 'EasyUseChatrooms', 'EasyUseSearch',\n",
    "               'EasyOther', 'WhyNotEasy', 'FeaturesWant', 'Helpopen', 'HelpAgile', 'HelpCollab', 'IsSecure',\n",
    "               'IsReliable', 'IsCompFunctional', 'IsAlignedGovGoals', 'IsGoodSourceInfo', 'IsGoodCentralHub', 'OtherBenefits'\n",
    "               ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfconnex['Aware'].value_counts()\n",
    "\n",
    "print (4057/(4057+802), \"% of participants are aware of GCconnex.\")\n",
    "print (\"I wouldn't be surprised if this was because most of the individuals saw the survey via the tools.\")\n",
    "print (\"There is some very likely bias in this answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nousegcconnex = dfconnex[dfconnex['UsageLength'] == \"Do not use at all\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nousegcconnex.describe(include = \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above table, several key insights come up. Many employees feel they don't know why GCconnex would be a useful tool for them. Also, many employees answer that the people they collaborate do not use it (no \"social\" in the network). Many felt that there was no purpose to using GCconnex.\n",
    "\n",
    "#### Compare using this with other social media habits\n",
    "It might be worthwhile to compare how employees who do not use GCconnex (but are aware of it) use other media. They may have a bias toward not liking social media or newer technologies, or maybe they don't like GCconnex for work purposes. Comparing GCconnex to other social media outlets (especially as a work tool) may help determine whether it is the individual or the tool that doesn't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nousegcconnex.to_csv(data_path+\"nouse.csv\") # Just to get a more thorough look at what's going on in the CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One useful tool to send to the dev team would be the user evaluations of the indivdiual aspects of GCconnex. It would be useful and simple to generate a report-card-like tool to the team, that allows them to see "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Let's do the dev thing\n",
    "dfdev = dfconnex.filter(regex = \"Easy\") #Extracts all the quesions that have the \"Easy\" thing. \n",
    "#I have a feeling this might be important to the dev team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfdev.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfdev.drop('WhyNotEasy', inplace = True, axis = 1)\n",
    "dfdev.drop('EasyOther', inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valuedict = {} #Taking the value counts of each question about easiness in here\n",
    "for col in dfdev:\n",
    "    valuedict[col] = dfdev[col].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "devfb = pd.DataFrame.from_dict(valuedict, orient = \"index\") #Turning the dictionary we just created into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "devfb = devfb.set_value('EasyInfo', \"Don't know / Not sure / Don't use\", 328) # Merging the \"Dont Know\" columns into one manually\n",
    "devfb = devfb.set_value('EasyUse', \"Don't know / Not sure / Don't use\", 257)\n",
    "devfb.drop(\"Don't know / Not sure\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now to reorder the columns because I'm pedantic like that\n",
    "devfb = devfb[['Yes', 'No', \"Don't know / Not sure / Don't use\"]]\n",
    "devfb[\"Don't know / Not sure / Don't use\"] = devfb[\"Don't know / Not sure / Don't use\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "devfb['Total'] = 0\n",
    "\n",
    "for i in devfb:\n",
    "    if i == 'Total':\n",
    "        break\n",
    "    else:\n",
    "        devfb['Total'] += devfb[i]\n",
    "\n",
    "        \n",
    "#Here is the table, the meanings are still a bit obscure to anyone except myself since I rewrote the names of all the columns\n",
    "#So before giving it to somebody else I'll fix the table index. But this is neat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "devfb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "devfb[['Yes', 'No']].plot.bar(stacked = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "devfbperc = devfb.apply(lambda x: x/devfb['Total']*100)\n",
    "grap1 = devfbperc[['Yes', 'No', \"Don't know / Not sure / Don't use\"]][0:9].plot.barh(stacked = True, figsize = [10,10])\n",
    "grap1.legend(loc = 'upper left', bbox_to_anchor=(1,1))\n",
    "grap1.set_title(\"What do users find easy?\")\n",
    "\n",
    "grap2 = devfbperc[['Yes', 'No', \"Don't know / Not sure / Don't use\"]][10:20].plot.barh(stacked = True, figsize = [10,10])\n",
    "grap2.legend(loc = 'upper left', bbox_to_anchor=(1,1))\n",
    "grap2.set_title(\"What do users find easy (cont)?\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ease of use by frequency, recency, (area of work)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Developer Feedback Table\n",
    "\n",
    "The above table can help us determine what the pain points are for GCconnex. The results that indicate 'Dont Know...' likely indicate that they don't use that functionality of the website. Whereas the \"No\" response indicates bad news. One unfortunate reality is the answer \"No\" To the EasyInfo response (long form: Easy to find the information you need) outweighs the \"Yes\". Perhaps there are some reasons in the comments, but that's not up to me to review.\n",
    "\n",
    "This is mirrored in the EasyinformationGroup row (long form: Easy to find information in groups). This response had more \"Yes\" than \"No,\" but not by a very large margin.\n",
    "\n",
    "Another unfortunate reality is the \"EasyUse\" row (long form: \"Did you find it [GCconnex] easy to use?\"). Most users gave a yes or no answer, but only 48% of responses indicated Yes, and 43% indicated No. \n",
    "\n",
    "On a more positive note, it appears many users find it easy to READ the content already posted on GCconnex. Passive activities such as View Image, Read Blog, Read Wire, and News Feed, all report a majority of affirmative responses. \n",
    "\n",
    "##### Observations\n",
    "\n",
    "If I'll be allowed to abstract from the responses, evidence of a Power Law phenomenon becomes apparent again. The Power Law dynamic as it applies to social networks implies that the majority of a user base will not create content on a network, however a small group of users will create a disproportionately large amount of content. Judging from the above responses, it appears that many users find it more simple to read content than to post content. This is obvious, since reading content is very passive and relatively effortless, however posting content is rather active. The fact that reading content is easier than posting content suggests the Power Law relationship is still very much present.\n",
    "\n",
    "The observation above is not to dismiss the troubling responses in the table above. It already takes great effort to post content onto GCconnex, since one must generate original and thoughtful responses and/or questions onto GCconnex. It should therefore be a priority for the tools team to make putting the original content onto GCconnex as simple as possible, something that can clearly be improved judging from the above responses.\n",
    "\n",
    "The troubling response to \"was it easy to find the information you needed\" indicates a problem.\n",
    "\n",
    "### The \"Is\" questions\n",
    "\n",
    "The survey asked many questions about their beliefs of GCconnex's usefulness. I've labeled these questions as \"is\" questions. Let's build a similar table for this. Btw, this is part of the exploratory data analysis. To build proper models that reflect the data, we should be able to get to know the data fairly well.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Building the is table\n",
    "\n",
    "dfis = dfconnex.filter(regex = \"Is\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#To get this over with really quickly, I'll just leave the values as is for now\n",
    "\n",
    "isdict = {}\n",
    "for col in dfis:\n",
    "    isdict[col] = dfis[col].value_counts()\n",
    "    \n",
    "istable = pd.DataFrame.from_dict(isdict, orient  = \"index\")\n",
    "istable = istable.reindex_axis(sorted(istable.columns), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Okay fine, I'll clean up the columns names\n",
    "collist  = list(istable.columns.values)\n",
    "\n",
    "collist = [c.replace(\"<br />\", \"\") for c in collist]\n",
    "    \n",
    "istable.columns = collist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "collist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "istable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Quick plot of the table\n",
    "ax = istable.plot(kind = \"bar\", title = \"User Responses to GCconnex 'is' Questions\")\n",
    "ax.legend(loc = 'upper left', bbox_to_anchor=(1,1))\n",
    "plt.show()\n",
    "\n",
    "#Also sidenote, you can plot dataframes directly from pandas, and this makes me unreasonably happy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Is\" Table\n",
    "\n",
    "The \"is\" table shows us what our sample group thinks about GCconnex as a tool. What we want to see is tall purple and yellow bars (the \"Moderately Agree\" and \"Strongly Agree\" responses). In each of the questions, users are still largely undecided as an aggregate. Most of the questions have more responses on the right side of 'undecided' rather than the left, indicating a slightly positive outlook on each of the questions (except for \"Is Completely Functional\").\n",
    "\n",
    "### \"Help\" Table\n",
    "\n",
    "Continuing our analysis with other factors from the survey.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "dfhelp = dfconnex.filter(regex = \"Help\")\n",
    "dfhelp\n",
    "\n",
    "helpdict = {}\n",
    "\n",
    "for col in dfhelp:\n",
    "    helpdict[col] = dfhelp[col].value_counts()\n",
    "\n",
    "helpcounts = pd.DataFrame.from_dict(helpdict, orient = \"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "helpcollist = [c.replace(\"<br />\", \"\") for c in list(helpcounts.columns)]\n",
    "helpcounts.columns = helpcollist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "helpcounts = helpcounts.reindex_axis(sorted(helpcounts.columns), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "helpcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax2 = helpcounts.plot.bar(title = \"User Responses if GCconnex Helps with...\")\n",
    "#Relatively High marks for collaboration!\n",
    "ax2.legend(loc = 'center left', bbox_to_anchor=(1,0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfuseinfo = dfconnex[dfconnex['WhyUseFindReUseInfo'] == 1]\n",
    "# Small tangent after speaking with Wahida. How many people who claim they use GCconnex to find information find search easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfuseinfo['EasyUseSearch'].value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use of GCconnex vs. Ease of features\n",
    "The above little digression makes me wonder if it would be easy to generate a series of crossplots (or even a crosstab) showing how people use GCconnex, and whether they find something easy or not. Variation in the ease of an operation that comes from the reason an individual uses GCconnex gives evidence of a learning curve, as well as whether the difficulty in using a feature stems from inexperience, or if it is just not simple to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#First Step is to pull the \"Why Use,\" aspect, which has lots of other stuff in it\n",
    "\n",
    "whyuse = dfconnex.filter(regex = \"WhyUse\")\n",
    "whyuse.drop('WhyUseReason', inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "whyuse['Participant'] = dfconnex['Participant']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfdev['Participant'] = dfconnex['Participant']\n",
    "\n",
    "EaseVsWhy = pd.merge(whyuse, dfdev, on = \"Participant\")\n",
    "\n",
    "#This has 34 columns, this might not work. I'll need to find a way to figure out how to do what I want to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "EaseVsWhy = EaseVsWhy.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " #I'm not sure if this will take me in the direction I want to go to be completely honest. \n",
    "# There's gotta be another less tedious way.\n",
    "\n",
    "# What if I made the index all of the easy, and dropped everything that wasn't yes?\n",
    "# Then it would be measuring the number of people who found it easy, and what they did. \n",
    "# I am so great."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "EaseVsWhy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "EaseVsWhy.replace(\"Yes\", 1, inplace = True)\n",
    "EaseVsWhy.replace(\"No\", 0, inplace = True)\n",
    "EaseVsWhy.replace(\"Don't know / Not sure / Don't use\", 0, inplace = True)\n",
    "EaseVsWhy.replace(\"Don't know / Not sure\", 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "EaseVsWhy = EaseVsWhy.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "whycols = []\n",
    "for col in EaseVsWhy.columns:\n",
    "    if \"Why\" in col:\n",
    "        whycols.append(col)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rubber Ducky\n",
    "\n",
    "I'm not really getting anywhere with what I want to do, so I'm gonna use a textual rubber ducky method here. \n",
    "\n",
    "The EaseVsWhy dataframe consists of columns asking why people use GCconnex, and columns asking whether they find a certain aspect EASY. If the individual answered yes to a question in each column, they get coded with a 1. Otherwise it is coded 0. My ideal dataframe would have the Why questions as the index, and each of the Ease questions in the columns. In the spaces where the columns are, I want the number of indiduals who found each task easy numbered by the reasons why they use GCconnex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "whylist = []\n",
    "for col in whycols:\n",
    "    whylist.append(EaseVsWhy[EaseVsWhy[col] == 1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Each element "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "whylistsums = []\n",
    "\n",
    "for why in whylist:\n",
    "    whylistsums.append(why.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "useandease = pd.DataFrame(whylistsums).filter(regex  = \"Easy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "useandease['WhyUse:'] = whycols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "useandease = useandease.set_index('WhyUse:', drop = True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ...What?\n",
    "\n",
    "If you're wondering what I just did above, so am I.\n",
    "\n",
    "The dataframe shows everyone who answered \"yes\" to the question in the index, why they use GCconnex. It then goes column by column, tallying up everyone who responded \"yes\" to the question whether they found a certain task easy in GCconnex.\n",
    "\n",
    "Lastly, because people could repsond that they use GCconnex for multiple things, one individual can be counted in several rows, but that's okay.\n",
    "\n",
    "It's still lacking one thing, we don't have a proportional answer. We should normalize each row by the amount of people who responded yes to each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "useandease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "useandease.apply(lambda x: max(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "whylistthings = EaseVsWhy.sum()[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "useandease['norm'] = whylistthings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "useeasenormed = useandease.apply(lambda x: x/useandease['norm']*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "useeasenormed.drop('norm', inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "useeasenormed.to_csv(data_path+'Ease of Tasks Depending on Use.csv') \n",
    "#This table gives the proportion of users who find each task easy depending on what they use GCconnex for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "useeasenormed.describe().to_csv(data_path+\"Ease of Tasks Depending on Use Summary Statistics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfconnex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use of tools and ease of tasks\n",
    "The tables above show how users' perceived ease of tasks of GCconnex depend on how they use GCconnex. For example, a significant amount of users who use GCconnex for chat found chat easy to use, however when they used GCconnex for other reasons, the reported ease of chat fell.\n",
    "\n",
    "Again, if a user uses GCconnex for both chat and career development, and they say chat is easy, that will count as a \"yes\" in both the chat and the career development rows. Nothing much can be done about that.\n",
    "\n",
    "Checking out the variation in responses in the columns is interesting. The ease of some tasks depends on the use, and for other responses, there isnt much variation depending on the use of tasks.\n",
    "\n",
    "\n",
    "\n",
    "# Demographic Data Cleaning\n",
    "\n",
    "I'm gonna look at demographic information to make sure it's cleaned up. This way, I can start playing with models soon. I don't want to do any models without having the controls of age, gender, time on public service etc. This will make (some) models more robust and help lend credence to the claims we will be making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "edcount.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "edcount = df3['Education']\n",
    "edcount = edcount.replace(\"Bachelor's degree\", \"Undergrad\")\n",
    "edcount = edcount.replace(\"University certificate or diploma above the bachelor's level including a master's degree or doctorate\", \"Masters/PhD\")\n",
    "edcount = edcount.replace(\"Diploma or certificate from a community college, CEGEP, institute of technology, nursing school, etc., or a trades certificate or diploma\", \"College/CEGEP/Certificate\")\n",
    "edcount = edcount.replace(\"Secondary or high school graduation certificate, equivalent or less\", \"High School or Lower\")\n",
    "edcount = edcount.replace(\"University certificate or diploma below the bachelor's level\", \"University < Bachelors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "edgraph = edcount.value_counts(sort = 'False')\n",
    "edgraph.sort_index(axis = 0, level = [['High School or Lower', 'Unversity < Bachelors', 'College/CEGEP/Certificate',\n",
    "                                       'Undergrad', 'Master/PhD']], inplace = True)\n",
    "\n",
    "edgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "edgraph.plot.bar()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataframe = pd.merge(df3, dfconnex, on = 'Participant') # I kind of forgot that I already did everything necessary for that.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is where I start having to be careful with what I'm doing as I progress further. I have 85 columns for the GCconnex study, which is all well and good, however I have to bear in mind that almost every single column is missing an observation. I have to go through the dataframe and figure out exactly how to go about cleaning the data.\n",
    "\n",
    "Some answers that lack responses should be filled with N/A instead. Other answers should be dropped if there is N/A. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataframe.to_csv(data_path+'Clean_File.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "I am going to perform the data cleaning with respect to a certain model in a different notebook. I don't want to put in too many things into one notebook. This was good for exploring what there is in the original file, and cleaning it up so that it is comprehensible for myself. I will likely return to this notebook when I want to look at the other GCTools (GCPedia, GCIntranet). A lot of the work for the other GCTools will build off what is already in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Databacked personas\n",
    "##### As per Martin's request\n",
    "\n",
    "- Data-driven stories about user types as described by the data. - Primary vs. Secondary Type of persona\n",
    "    - How use site? \n",
    "    - Proficiency of social media.\n",
    "    - Content/ Information needs\n",
    "    - What are they looking for?\n",
    " \n",
    " \n",
    "- Open ended comments\n",
    "    - Format, see if can combine with closed content questions\n",
    "    - Pull out (NLTK) and read.\n",
    "\n",
    "\n",
    "- Anti-persona\n",
    "    - User better served by other site. (Proxy by non-usage of GCconnex?)\n",
    "        - Might come out of open ended comments anyway.\n",
    "    - Important\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
