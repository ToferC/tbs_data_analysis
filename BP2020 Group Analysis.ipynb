{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import powerlaw\n",
    "import csv\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
    "from matplotlib.dates import date2num\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = r'/Users/Owner/Documents/Work_transfer/Data/GCconnex/'\n",
    "keys_path = r'/Users/Owner/Documents/Work_transfer/Data/GCconnex/Profile Statistics/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BP = pd.read_csv(data_path+'BP2020 data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Making a 'groups' dataset isolates some cool info we can pull from them\n",
    "BPgroups = BP[BP.department == 'group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Weighted Degree</th>\n",
       "      <th>Weighted In-Degree</th>\n",
       "      <th>Weighted Out-Degree</th>\n",
       "      <th>In-Degree</th>\n",
       "      <th>Out-Degree</th>\n",
       "      <th>Degree</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>Closeness Centrality</th>\n",
       "      <th>Betweenness Centrality</th>\n",
       "      <th>Eigenvector Centrality</th>\n",
       "      <th>Clustering Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3208.000000</td>\n",
       "      <td>3208.000000</td>\n",
       "      <td>3208.000000</td>\n",
       "      <td>3208.000000</td>\n",
       "      <td>3208.000000</td>\n",
       "      <td>3208.000000</td>\n",
       "      <td>3208.000000</td>\n",
       "      <td>3208.000000</td>\n",
       "      <td>3208.000000</td>\n",
       "      <td>3208.000000</td>\n",
       "      <td>3208.000000</td>\n",
       "      <td>3208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5109649.106297</td>\n",
       "      <td>35.829177</td>\n",
       "      <td>34.828242</td>\n",
       "      <td>1.000935</td>\n",
       "      <td>34.828242</td>\n",
       "      <td>1.000935</td>\n",
       "      <td>35.829177</td>\n",
       "      <td>26.769327</td>\n",
       "      <td>9.150913</td>\n",
       "      <td>239650.665809</td>\n",
       "      <td>0.006763</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3708994.522046</td>\n",
       "      <td>152.300325</td>\n",
       "      <td>152.300431</td>\n",
       "      <td>0.030571</td>\n",
       "      <td>152.300431</td>\n",
       "      <td>0.030571</td>\n",
       "      <td>152.300325</td>\n",
       "      <td>7.445872</td>\n",
       "      <td>2.496518</td>\n",
       "      <td>1163880.241701</td>\n",
       "      <td>0.029440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>122.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2039915.250000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>8.914204</td>\n",
       "      <td>2109.601109</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4785059.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>9.532337</td>\n",
       "      <td>29382.069259</td>\n",
       "      <td>0.001939</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7284828.500000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>10.262739</td>\n",
       "      <td>145394.263235</td>\n",
       "      <td>0.004702</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13163685.000000</td>\n",
       "      <td>5177.000000</td>\n",
       "      <td>5176.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5176.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5177.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>16.279275</td>\n",
       "      <td>37181843.706094</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Id  Weighted Degree  Weighted In-Degree  \\\n",
       "count      3208.000000      3208.000000         3208.000000   \n",
       "mean    5109649.106297        35.829177           34.828242   \n",
       "std     3708994.522046       152.300325          152.300431   \n",
       "min         122.000000         1.000000            0.000000   \n",
       "25%     2039915.250000         5.000000            4.000000   \n",
       "50%     4785059.000000        11.000000           10.000000   \n",
       "75%     7284828.500000        25.000000           24.000000   \n",
       "max    13163685.000000      5177.000000         5176.000000   \n",
       "\n",
       "       Weighted Out-Degree    In-Degree   Out-Degree       Degree  \\\n",
       "count          3208.000000  3208.000000  3208.000000  3208.000000   \n",
       "mean              1.000935    34.828242     1.000935    35.829177   \n",
       "std               0.030571   152.300431     0.030571   152.300325   \n",
       "min               1.000000     0.000000     1.000000     1.000000   \n",
       "25%               1.000000     4.000000     1.000000     5.000000   \n",
       "50%               1.000000    10.000000     1.000000    11.000000   \n",
       "75%               1.000000    24.000000     1.000000    25.000000   \n",
       "max               2.000000  5176.000000     2.000000  5177.000000   \n",
       "\n",
       "       Eccentricity  Closeness Centrality  Betweenness Centrality  \\\n",
       "count   3208.000000           3208.000000             3208.000000   \n",
       "mean      26.769327              9.150913           239650.665809   \n",
       "std        7.445872              2.496518          1163880.241701   \n",
       "min        1.000000              1.000000                0.000000   \n",
       "25%       27.000000              8.914204             2109.601109   \n",
       "50%       29.000000              9.532337            29382.069259   \n",
       "75%       29.000000             10.262739           145394.263235   \n",
       "max       35.000000             16.279275         37181843.706094   \n",
       "\n",
       "       Eigenvector Centrality  Clustering Coefficient  \n",
       "count             3208.000000                    3208  \n",
       "mean                 0.006763                       0  \n",
       "std                  0.029440                       0  \n",
       "min                  0.000000                       0  \n",
       "25%                  0.000770                       0  \n",
       "50%                  0.001939                       0  \n",
       "75%                  0.004702                       0  \n",
       "max                  1.000000                       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BPgroups.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Next lines of Code are converting all emails into actual departments.\n",
    "#It still doesn't mitigate the issue of the canada.ca domain, but it aggregates all the emails into their proper departments\n",
    "BP['department'] = BP['department'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dept = BP.department\n",
    "dept_sort = set(dept)\n",
    "dept_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(keys_path, \"csv_keys.csv\"), \"r\") as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    next(reader)\n",
    "    \n",
    "    for row in reader:\n",
    "        email, acronym = row\n",
    "        dept_dict[email] = acronym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dept_dict['cadets.gc.ca'] = 'CADETS'\n",
    "dept_dict['canada.gc.ca'] = 'CANADA'\n",
    "dept_dict['canada.ca'] = 'CANADA'\n",
    "dept_dict['tribunal.gc.ca'] = 'TRIBUNAL'\n",
    "dept_dict['cannor.gc.ca'] = 'CED/DEC'\n",
    "dept_dict['ci-oic.gc.ca'] = 'CI/OIC'\n",
    "dept_dict['ccgs-ngcc.gc.ca'] = 'CCGS/NGCC'\n",
    "dept_dict['god.ccgs-ngcc.gc.ca'] = 'CCGS/NGCC'\n",
    "dept_dict['clo-ocol.gc.ca'] = 'OCOL/CLO'\n",
    "dept_dict['csps.gc.ca'] = 'CSPS/EFPC'\n",
    "dept_dict['interenational.gc.ca'] = 'DFAITD/MAECD'\n",
    "dept_dict['cnb-ncw.gc.ca'] = 'CNB/NCW'\n",
    "dept_dict['ncw-cnb.gc.ca'] = 'CNB/NCW'\n",
    "dept_dict['nfb.gc.ca'] = 'NFB/ONF'\n",
    "dept_dict['nrccan-rncan.gc.ca'] = 'NRCAN/RNCAN'\n",
    "dept_dict['nserc-crsng.gc.ca'] = 'NSERC/CRSNG'\n",
    "dept_dict['pbc-clcc.gc.ca'] = 'PBC/CLCC'\n",
    "dept_dict['pco.bcp.gc.ca'] = 'PCO/BCP'\n",
    "dept_dict['pipsc.ca'] = 'PIPSC/IPFPC'\n",
    "dept_dict['ps.sp.gc.ca'] = 'PS/SP'\n",
    "dept_dict['servicecanada.gc.ca.gc.ca'] = 'HRSDC/RHDSC'\n",
    "dept_dict['fintrac-canafe.gc.ca'] = 'FINTRAC'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dep = pd.DataFrame.from_dict(dept_dict, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BP = BP.replace({'department': dept_dict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n"
     ]
    }
   ],
   "source": [
    "department = BP[BP.department != 'group']\n",
    "depcount = department['department'].value_counts()\n",
    "print (len(depcount))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#There are 96 different departments registered to BP2020\n",
    "depcount.to_csv(data_path+'BP2020 Department Count.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "department.to_csv(data_path+'BP2020 Users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Pulling Back the groups dataset, we can plot all the sorts of distributions of the groups to get some visualizations\n",
    "#On who BP2020 is connecting to\n",
    "BPgroups = BPgroups.reset_index()\n",
    "BPgroups.drop('index', 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BPgroupsdegdist = BPgroups['In-Degree']\n",
    "BPgroupsdegdist = BPgroupsdegdist.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3208\n",
      "3208\n",
      "We're good to go!\n"
     ]
    }
   ],
   "source": [
    "BPgroupsdegdist\n",
    "print (sum(BPgroupsdegdist))\n",
    "print (len(BPgroups))\n",
    "if sum(BPgroupsdegdist) == len(BPgroups):\n",
    "    print (\"We're good to go!\")\n",
    "else:\n",
    "    print (\"You did something wrong here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Network simulation of Barabasi Albert Graph\n",
    "G = nx.barabasi_albert_graph(5500, 3)\n",
    "G_histo = nx.degree_histogram(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Run this, use the built-in editor to get the format I'm happy with, then export it\n",
    "plt.scatter(np.arange(len(BPgroupsdegdist)), BPgroupsdegdist, color='r')\n",
    "plt.scatter(np.arange(len(G_histo)), G_histo)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x-fit:\n",
      "1.0\n",
      "Alpha (Distribution Coefficient:)\n",
      "1.55466228166\n",
      "Fit comparison\n",
      "(7.5190536767298175, 5.5174131624906334e-14)\n",
      "(-2.5984096325114234, 0.0093656693006935795)\n"
     ]
    }
   ],
   "source": [
    "#Now to test whether or not the function is factually a power-law distribution, or just an exponential\n",
    "#And now testing for lognormal distributions\n",
    "groupsfit = powerlaw.Fit(BPgroupsdegdist, discrete=True, xmin=1)\n",
    "print (\"x-fit:\")\n",
    "print (groupsfit.xmin)\n",
    "print (\"Alpha (Distribution Coefficient:)\")\n",
    "print (groupsfit.power_law.alpha)\n",
    "print (\"Fit comparison\")\n",
    "print (groupsfit.distribution_compare('power_law', 'exponential', normalized_ratio=True))\n",
    "print (groupsfit.distribution_compare('power_law', 'lognormal', normalized_ratio=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Let's play with this lognormal distribution...\n",
    "numbers = np.arange(1, len(BPgroupsdegdist) + 1)\n",
    "lognorm = pd.DataFrame(data = BPgroupsdegdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This is just to illustrate the fitting of the power-law distribution. It fits nicely, but apparently now as nice as lognormal\n",
    "fig1 = groupsfit.plot_pdf(color='b', linewidth=2)\n",
    "groupsfit.power_law.plot_pdf(color='b', linestyle='--', ax=fig1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BPEC = BPgroups.sort('Eigenvector Centrality', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Identifying the departments that join the most groups proportional to their size\n",
    "#Group joining is being used as a proxy to involvement in this dataset.\n",
    "depgrouping = department.groupby('department').mean()\n",
    "depgrouping.drop('Id', 1, inplace=True)\n",
    "depgrouping.sort('Degree', inplace=True, ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Identifying the most contributive departments in total\n",
    "depgroupingsum = department.groupby('department').sum()\n",
    "depgroupingsum.drop('Id', 1, inplace=True)\n",
    "depgroupingsum.sort('Degree', inplace=True, ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "depdegdist = department['Out-Degree']\n",
    "depdegdist = depdegdist.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x-fit:\n",
      "3.0\n",
      "Alpha (Distribution Coefficient:)\n",
      "1.43082424306\n",
      "Fit comparison\n",
      "(2.9514588925473082, 0.0031627664217491426)\n",
      "(-1.5270101716442854, 0.12675848207731819)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating best minimal value for power law fit\n"
     ]
    }
   ],
   "source": [
    "#Running the powerlaw distribution fit, except this time we see that the fit is not as neat as power-law fit for groups\n",
    "#In fact, this distribution does not seem to lead to a power-law distribution at all\n",
    "#More research is going to need to be done in order to gather significant meaning from this\n",
    "degfit = powerlaw.Fit(depdegdist, discrete=True)\n",
    "print (\"x-fit:\")\n",
    "print (degfit.xmin)\n",
    "print (\"Alpha (Distribution Coefficient:)\")\n",
    "print (degfit.power_law.alpha)\n",
    "print (\"Fit comparison\")\n",
    "print (degfit.distribution_compare('power_law', 'exponential', normalized_ratio=True))\n",
    "print (degfit.distribution_compare('power_law', 'lognormal', normalized_ratio=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(np.arange(len(depdegdist)), depdegdist)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Who are the most involved in the network that are joined to Blueprint 2020\n",
    "#Those who are in many groups have a lot of reach, as groups are the main forum for serious collaborative discussion\n",
    "#The only issue is because this is a directed graph, tracing the number of shortest paths is not possible\n",
    "involved = department.sort('Out-Degree', ascending=False)\n",
    "involved.to_csv(data_path+'Involvedmembers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#The original graph was run as a directed graph, to differentiate between creating groups and joining groups\n",
    "#This however does not work for a correlation analysis of out-degree and betweenness centrality, so a new graph must be imported\n",
    "bc = pd.read_csv(data_path+'BP2020 BC.csv')\n",
    "bc = bc[bc.department != 'group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = bc['Weighted Out-Degree']\n",
    "y = bc['Betweenness Centrality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#When we plot Betweenness Centrality and Out-Degree we get a confirmation that the best situated members are those who\n",
    "#Have joined and been involved with many groups\n",
    "plt.scatter(y,x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.713\n",
      "Model:                            OLS   Adj. R-squared:                  0.713\n",
      "Method:                 Least Squares   F-statistic:                 1.288e+04\n",
      "Date:                Mon, 02 Nov 2015   Prob (F-statistic):               0.00\n",
      "Time:                        14:37:34   Log-Likelihood:                -69977.\n",
      "No. Observations:                5176   AIC:                         1.400e+05\n",
      "Df Residuals:                    5174   BIC:                         1.400e+05\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      -7e+04   3326.411    -21.044      0.000     -7.65e+04 -6.35e+04\n",
      "x           3.745e+04    329.949    113.494      0.000      3.68e+04  3.81e+04\n",
      "==============================================================================\n",
      "Omnibus:                     5302.281   Durbin-Watson:                   2.012\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           832850.452\n",
      "Skew:                           4.696   Prob(JB):                         0.00\n",
      "Kurtosis:                      64.429   Cond. No.                         13.5\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#And because visually confirming relationships is a serious no-no, we have a regression that also says the same thing\n",
    "#Intuitively, visually and empirically we can say that the best people to target are the ones who \n",
    "model = smf.ols(formula = 'y ~ x', data = bc)\n",
    "results = model.fit()\n",
    "print (results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#With this, we can say that the people who join the most groups are very likely to be the most central ones in the network\n",
    "#In the context of this analysis, this means we can say that people who join the most groups likely have the best reach\n",
    "#Obviously this makes perfect sense "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Comparing a distribution of groups joined with the rest of the network\n",
    "comp = pd.read_csv('/Users/Owner/Documents/Work_transfer/Data/Report Card/Anonindstats.csv')\n",
    "gjcomp = comp['Groups Joined'].value_counts()\n",
    "gjcomp = gjcomp[1:]\n",
    "plt.plot(gjcomp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x-fit:\n",
      "4.0\n",
      "Alpha (Distribution Coefficient:)\n",
      "1.36853843016\n",
      "Fit comparison\n",
      "(4.847905698428022, 1.2477168315602152e-06)\n",
      "(-0.91205953043798649, 0.36173738063069161)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating best minimal value for power law fit\n"
     ]
    }
   ],
   "source": [
    "gjresult = powerlaw.Fit(gjcomp, discrete=True)\n",
    "print (\"x-fit:\")\n",
    "print (gjresult.xmin)\n",
    "print (\"Alpha (Distribution Coefficient:)\")\n",
    "print (gjresult.power_law.alpha)\n",
    "print (\"Fit comparison\")\n",
    "print (gjresult.distribution_compare('power_law', 'exponential', normalized_ratio=True))\n",
    "print (gjresult.distribution_compare('power_law', 'lognormal', normalized_ratio=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Pulling data of all the comments made in the network, filtering out only for people in the Blueprint Group\n",
    "commentcsv = pd.read_excel('/Users/Owner/Documents/Work_transfer/Data/Report Card/comments.xlsx')\n",
    "comments = commentcsv[['owner_guid', 'string']]\n",
    "comments.columns = ['Id', 'String']\n",
    "commentcount = comments.groupby('Id').count()\n",
    "commentcount.reset_index(inplace=True)\n",
    "commentcount = commentcount.convert_objects(convert_numeric = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9976\n"
     ]
    }
   ],
   "source": [
    "\n",
    "depdegree = department[['Id', 'In-Degree', 'Out-Degree']]\n",
    "idbt = pd.merge(depdegree, commentcount, how='outer', on = 'Id')\n",
    "print (len(idbt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5176\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/Users/Owner/Documents/Work_transfer/Data/GCconnex/Commenters.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-44c468ac4f1f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0midbt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'User GUID'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'In-Degree'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Out-Degree'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Comments'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midbt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0midbt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'Commenters.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal, **kwds)\u001b[0m\n\u001b[0;32m   1187\u001b[0m                                      \u001b[0mescapechar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mescapechar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m                                      decimal=decimal)\n\u001b[1;32m-> 1189\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1191\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\pandas\\core\\format.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1440\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m             f = com._get_handle(self.path_or_buf, self.mode,\n\u001b[1;32m-> 1442\u001b[1;33m                                 encoding=self.encoding)\n\u001b[0m\u001b[0;32m   1443\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\pandas\\core\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path, mode, encoding, compression)\u001b[0m\n\u001b[0;32m   2827\u001b[0m                 \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m                 \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'replace'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/Users/Owner/Documents/Work_transfer/Data/GCconnex/Commenters.csv'"
     ]
    }
   ],
   "source": [
    "#The logic behind this is that idbt is a table that consists of of the amount of comments every user in BP2020 hsa made\n",
    "#and the amount of groups that each member joined, for the purposes of a regression analysis\n",
    "idbt = idbt.dropna(subset=['Out-Degree'], how='all') #If the group member did had an out-degree of NaN it's because that \n",
    "#individual was not in the original BP2020 group member dataset, so they were not part of the group. So we drop them.\n",
    "idbt = idbt.fillna(0)\n",
    "idbt.columns = ['User GUID', 'In-Degree', 'Out-Degree', 'Comments']\n",
    "print (len(idbt))\n",
    "idbt.to_csv(data_path+'Commenters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "commenters = idbt[idbt['Comments'] > 0]\n",
    "print (\"Of the 5176 members of Blueprint 2020, only\", len(commenters), \"Members have at least one comment. That is only\",(len(commenters)/len(idbt))*100,\"% of the group\")\n",
    "idbt['Comments'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = idbt['Out-Degree']\n",
    "y= idbt['Comments']\n",
    "z = idbt['In-Degree']\n",
    "model = smf.ols(formula = 'y ~ x + z', data = idbt)\n",
    "results = model.fit()\n",
    "print (results.summary())\n",
    "#The amount of comments a person makes is correlated with group involvement, but not incredibly so\n",
    "#The R-Squared value shows that this is not the best predictor there ever was"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#But if we remove the 73.8% of people who don't comment\n",
    "idbt1 = idbt[idbt['Comments'] > 0]\n",
    "x = idbt1['Out-Degree']\n",
    "y= idbt1['Comments']\n",
    "z = idbt1['In-Degree']\n",
    "model = smf.ols(formula = 'y ~ x + z', data = idbt1)\n",
    "results = model.fit()\n",
    "print (results.summary())\n",
    "#If we only factor in those who HAVE commented, then we see that creating groups\n",
    "# Group creating and the intercept are not statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This means that the biggest, most central players within BP2020 and the GCconnex itself are the ones with\n",
    "#the most groups joined. It gives them the most exposure throughout the network, and generally can mean that they are\n",
    "#involved\n",
    "\n",
    "#But with this new-found knowledge, we can start saying for sure that the most important people throughout the network\n",
    "#Are the ones who have many different groups joined.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.plot(x, np.poly1d(np.polyfit(x,y,1))(x), color='r')\n",
    "plt.plot(y, np.poly1d(np.polyfit(y,x,1))(y), color='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idbt.sort('Comments', inplace=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2013-05-15', '2013-05-16', '2013-05-17', '2013-05-18',\n",
       "               '2013-05-19', '2013-05-20', '2013-05-21', '2013-05-22',\n",
       "               '2013-05-23', '2013-05-24', \n",
       "               ...\n",
       "               '2015-10-22', '2015-10-23', '2015-10-24', '2015-10-25',\n",
       "               '2015-10-26', '2015-10-27', '2015-10-28', '2015-10-29',\n",
       "               '2015-10-30', '2015-10-31'],\n",
       "              dtype='datetime64[ns]', length=900, freq='D', tz=None)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's not stop the party here though... We can go deeper..\n",
    "\n",
    "groups = pd.read_csv(data_path+'Group Members GCconnex.csv')\n",
    "colleagues = pd.read_csv(data_path+'Colleagues GCconnex.csv')\n",
    "BP2020_members = groups[(groups['Group GUID'] == 272967)]\n",
    "datetime = pd.date_range('2013-05-15', periods = 900, freq='D')\n",
    "datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "memberlist = BP2020_members['User GUID'].tolist()\n",
    "bpcolleaguesnw = colleagues[(colleagues['UID1'].isin(memberlist)) & (colleagues['UID2'].isin(memberlist))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19574\n",
      "83111\n"
     ]
    }
   ],
   "source": [
    "#Within the web of the 5300+ employees, there are 19574  colleague\n",
    "print(len(bpcolleaguesnw))\n",
    "bpcolleagues1 = colleagues[(colleagues['UID1'].isin(memberlist))]\n",
    "bpcolleagues2 = colleagues[(colleagues['UID2'].isin(memberlist))]\n",
    "collist = [bpcolleagues1, bpcolleagues2]\n",
    "bpcolleagues = pd.concat(collist)\n",
    "bpcolleagues.drop_duplicates(inplace = True)\n",
    "print (len(bpcolleagues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We have to do a little more massaging with the data\n",
    "#The issue with the colleagues dataset is that it tends to double count friend lists (because 1 -> 2, then to accept 2 -> 1)\n",
    "#These next few cells runs through the datasets, and deletes the double counting in the dataset\n",
    "\n",
    "#It's all blocked atm because the code is woefully inefficient and it takes forever to run!\n",
    "#The results are printed in the code file\n",
    "\n",
    "#swag = bpcolleaguesnw[['UID1', 'UID2']].values.tolist()\n",
    "#print (swag[0:5])\n",
    "#a = [[0, 1], [1, 0], [1, 2], [2, 1], [2, 3], [3, 2], [3, 4], [4, 3], [5, 6], [6, 7], [7, 8], [8, 7]]\n",
    "#print (a)\n",
    "#for x in a:\n",
    "#    y = [x[1], x[0]]\n",
    "#    if y in a:\n",
    "#        a.remove(x)\n",
    "#print (a)\n",
    "\n",
    "#for x in swag:\n",
    "#    y = [x[1], x[0]]\n",
    "#    if y in swag:\n",
    "#        swag.remove(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print (len(swag))\n",
    "#for x in swag:\n",
    "#    y = [x[1], x[0]]\n",
    "#    if y in swag:\n",
    "#        swag.remove(x)\n",
    "#print (len(swag))\n",
    "#for x in swag:\n",
    "#    y = [x[1], x[0]]\n",
    "#    if y in swag:\n",
    "#        swag.remove(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This means that there are 13141 connections between blueprint 2020 members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#bpcolleaguesfixed = pd.DataFrame(swag)\n",
    "#bpcolleaguesfixed\n",
    "#bpcolleaguesfixed.columns = ['UID1', 'UID2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We have to do a little more massaging with the data\n",
    "#swagger = colleagues[['UID1', 'UID2']].values.tolist()\n",
    "#print (swag[0:5])\n",
    "\n",
    "\n",
    "#for x in swagger:\n",
    "#    y = [x[1], x[0]]\n",
    "#    if y in swagger:\n",
    "#        swagger.remove(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#swaggy = bpcolleagues[['UID1', 'UID2']].values.tolist()\n",
    "\n",
    "#for x in swaggy:\n",
    "#    y = [x[1], x[0]]\n",
    "#    if y in swaggy:\n",
    "#        swaggy.remove(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print (len(swagger))\n",
    "#print (len(swag)/len(swagger))\n",
    "#print (len(swaggy)/len(swagger))\n",
    "\n",
    "#Number of Colleague Matches is 127673 (instead of 187000)\n",
    "#Percentage of BP2020 colleagues between bp2020 members only is 10.29%\n",
    "#Percentage of colleague links with at least one BP2020 member is 45.60%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "83111\n",
      "187781\n",
      "0.442595363748196\n"
     ]
    }
   ],
   "source": [
    "test = len(bpcolleagues[bpcolleagues.duplicated() == True])\n",
    "print (test)\n",
    "print (len(bpcolleagues))\n",
    "print (len(colleagues))\n",
    "print (len(bpcolleagues)/len(colleagues))\n",
    "#If my coding is right, then BP2020 members make up 44 percent of all colleague requests\n",
    "#I'll check this later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Awww yis, clean data\n"
     ]
    }
   ],
   "source": [
    "#Looking at growth of members over time\n",
    "corruptentries = BP2020_members[BP2020_members['Date'] == '1969-12-31']\n",
    "print (len(corruptentries))\n",
    "if len(corruptentries) == 0:\n",
    "    print (\"Awww yis, clean data\")\n",
    "else:\n",
    "    print (\"Of course, we can't escape corruption :(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "BP2020_members['Date'] = pd.to_datetime(BP2020_members['Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regdate = BP2020_members.groupby(BP2020_members.Date).count()\n",
    "regdate = regdate.reindex(datetime, fill_value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regdate['Member'] = regdate['Member'].cumsum()\n",
    "regdate.drop('Group GUID', 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns = ['Registrations', 'Cumulative Sum']\n",
    "regdate.columns = columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Plotting the size of blueprint 2020 over time\n",
    "line = plt.plot_date(datetime, regdate['Cumulative Sum'], linewidth=1, antialiased=False, linestyle='-')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Group Members')\n",
    "plt.title('Blueprint 2020 Group Growth')\n",
    "sns.plotting_context(context=\"notebook\")\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Doing the same thing with colleagues would be inaccurate because of untimely database corruptions\n",
    "#Plus I don't believe it would be that helpful in any case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "colldate = bpcolleagues[bpcolleagues['Date'] != '1969-12-31']\n",
    "colldate['Date'] = pd.to_datetime(bpcolleagues['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colldate = colldate.groupby('Date').count()\n",
    "colldate = colldate.reindex(datetime, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colldate['Friend'] = colldate['Friend'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colldate.drop('UID2', 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py:475: UserWarning: No labelled objects found. Use label='...' kwarg on individual plots.\n",
      "  warnings.warn(\"No labelled objects found. \"\n"
     ]
    }
   ],
   "source": [
    "Group_Size = plt.plot_date(datetime, regdate['Cumulative Sum'], antialiased=True)\n",
    "Colleague_Requests = plt.plot_date(datetime, colldate['Friend'], antialiased=True)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Actions')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5864 groups in GCconnex\n"
     ]
    }
   ],
   "source": [
    "groupslist = groups.groupby('Group GUID').count()\n",
    "print (\"There are\", len(groupslist),\"groups in GCconnex\")\n",
    "groupslist.sort('Member', ascending=False)\n",
    "bp2020grouplist = groups[groups['User GUID'].isin(memberlist)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bp2020grouplist = bp2020grouplist.groupby('Group GUID').count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bp2020grouplist.sort('Member', ascending=False)\n",
    "bp2020grouplist.columns = ['1','2','3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bp2020grouplist = bp2020grouplist.join(groupslist, how='left', on=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bp2020grouplist = bp2020grouplist[['1', 'User GUID']]\n",
    "bp2020grouplist.columns = ['BPMembers', 'Group Members']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Yeah this doesn't give very good data.\n",
    "bp2020grouplist = bp2020grouplist.sort('BPMembers', ascending=False)\n",
    "bp2020grouplist['Percentage'] = bp2020grouplist['BPMembers']/bp2020grouplist['Group Members']*100\n",
    "bp2020grouplist.sort('Percentage', ascending=False)\n",
    "bplist = bp2020grouplist[bp2020grouplist['BPMembers'] > 50]\n",
    "bplist = bplist.sort('Percentage', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#In the report, I make a reference to the percentage of users who have not made a comment in BP2020 and compare it\n",
    "#to the network as a whole. The issue though, is that there is a sampling bias. If someone registered, and did not joing a group\n",
    "#then they are much less likely to make a comment anywhere. To control for this, we are going to do a conditional\n",
    "#probability analysis, where I am going to obtain the probability that a user makes a comment given that they have joined a group\n",
    "# This is noted as P(Comment | Joined a group) which is equal to P(commented and joined a group)/P(joined a group)\n",
    "#This is effectively just controlling for the fact in BP2020, people have joined a group,whereas in the network, that's not\n",
    "#always the case\n",
    "\n",
    "#The issue here is that for some weird reason the data is inconsistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72815\n"
     ]
    }
   ],
   "source": [
    "#Making a table to start calculating probabilities\n",
    "groups_joined = comp[['User GUID','Groups Joined']]\n",
    "comments_ = commentcount \n",
    "comments_.columns = ['User GUID', 'Comments'] \n",
    "probdf = pd.merge(groups_joined, comments_, on='User GUID', how='outer')\n",
    "probdf = probdf.dropna(axis=0, how='any', subset=['User GUID'])\n",
    "probdf = probdf.fillna(0) #Those who didn't have a comment were not in the table of comments, so fillna makes them zero\n",
    "print (len(probdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability that a random user has joined a group is 0.6327542401977615\n",
      "The probability that a random user has made a comment is 0.08439195220764953\n",
      "The probability that a random user has done both is 0.08025818856004945\n",
      "The probability that a user comments given that they've joined a group is 0.1268394322177367\n"
     ]
    }
   ],
   "source": [
    "#Probability they have joined a group\n",
    "pg = len(probdf[probdf['Groups Joined'] >= 1])/len(probdf)\n",
    "#probability that they have made a comment\n",
    "pc = len(probdf[probdf['Comments'] >= 1])/len(probdf)\n",
    "#Probability that they've done both\n",
    "pgc = len(probdf[(probdf['Comments'] >= 1) & (probdf['Groups Joined'] >= 1)])/len(probdf)\n",
    "\n",
    "pcgiveng = pgc/pg\n",
    "print (\"The probability that a random user has joined a group is\",pg)\n",
    "print (\"The probability that a random user has made a comment is\",pc)\n",
    "print (\"The probability that a random user has done both is\",pgc)\n",
    "print (\"The probability that a user comments given that they've joined a group is\",pcgiveng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26741\n",
      "66670\n",
      "72815\n"
     ]
    }
   ],
   "source": [
    "print (len(probdf[probdf['Groups Joined'] == 0]))\n",
    "print (len(probdf[probdf['Comments'] == 0]))\n",
    "print (len(probdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
